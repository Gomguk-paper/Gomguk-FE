import type { Paper, Summary, Report } from "./index";

export const papers: Paper[] = [
  {
    id: "p1",
    title: "Attention Is All You Need",
    authors: ["Vaswani, A.", "Shazeer, N.", "Parmar, N."],
    year: 2017,
    venue: "NeurIPS",
    tags: ["Transformer", "NLP", "Attention"],
    abstract: "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...",
    pdfUrl: "https://arxiv.org/pdf/1706.03762",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 95, recencyScore: 60, citations: 85000 },
  },
  {
    id: "p2",
    title: "BERT: Pre-training of Deep Bidirectional Transformers",
    authors: ["Devlin, J.", "Chang, M.", "Lee, K."],
    year: 2019,
    venue: "NAACL",
    tags: ["NLP", "Transformer", "Pre-training"],
    abstract: "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers...",
    pdfUrl: "https://arxiv.org/pdf/1810.04805",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 88, recencyScore: 65, citations: 65000 },
  },
  {
    id: "p3",
    title: "Denoising Diffusion Probabilistic Models",
    authors: ["Ho, J.", "Jain, A.", "Abbeel, P."],
    year: 2020,
    venue: "NeurIPS",
    tags: ["Diffusion", "Generative", "Vision"],
    abstract: "We present high quality image synthesis results using diffusion probabilistic models...",
    pdfUrl: "https://arxiv.org/pdf/2006.11239",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 92, recencyScore: 75, citations: 12000 },
  },
  {
    id: "p4",
    title: "Proximal Policy Optimization Algorithms",
    authors: ["Schulman, J.", "Wolski, F.", "Dhariwal, P."],
    year: 2017,
    venue: "arXiv",
    tags: ["RL", "Policy Gradient", "Optimization"],
    abstract: "We propose a new family of policy gradient methods for reinforcement learning...",
    pdfUrl: "https://arxiv.org/pdf/1707.06347",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 85, recencyScore: 55, citations: 18000 },
  },
  {
    id: "p5",
    title: "Vision Transformer (ViT)",
    authors: ["Dosovitskiy, A.", "Beyer, L.", "Kolesnikov, A."],
    year: 2021,
    venue: "ICLR",
    tags: ["Vision", "Transformer", "Image Classification"],
    abstract: "While the Transformer architecture has become the de-facto standard for NLP tasks, its applications to computer vision remain limited...",
    pdfUrl: "https://arxiv.org/pdf/2010.11929",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 90, recencyScore: 80, citations: 22000 },
  },
  {
    id: "p6",
    title: "GPT-4 Technical Report",
    authors: ["OpenAI"],
    year: 2023,
    venue: "arXiv",
    tags: ["LLM", "Multimodal", "Scaling"],
    abstract: "We report the development of GPT-4, a large-scale multimodal model which can accept image and text inputs...",
    pdfUrl: "https://arxiv.org/pdf/2303.08774",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 98, recencyScore: 95, citations: 8000 },
  },
  {
    id: "p7",
    title: "Reinforcement Learning from Human Feedback",
    authors: ["Christiano, P.", "Leike, J.", "Brown, T."],
    year: 2017,
    venue: "NeurIPS",
    tags: ["RL", "RLHF", "Human Feedback"],
    abstract: "For sophisticated reinforcement learning systems to interact usefully with real-world environments...",
    pdfUrl: "https://arxiv.org/pdf/1706.03741",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 94, recencyScore: 70, citations: 5000 },
  },
  {
    id: "p8",
    title: "Stable Diffusion",
    authors: ["Rombach, R.", "Blattmann, A.", "Lorenz, D."],
    year: 2022,
    venue: "CVPR",
    tags: ["Diffusion", "Vision", "Generative"],
    abstract: "We present high-resolution image synthesis with latent diffusion models...",
    pdfUrl: "https://arxiv.org/pdf/2112.10752",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 96, recencyScore: 88, citations: 15000 },
  },
  {
    id: "p9",
    title: "Chain-of-Thought Prompting",
    authors: ["Wei, J.", "Wang, X.", "Schuurmans, D."],
    year: 2022,
    venue: "NeurIPS",
    tags: ["LLM", "Prompting", "Reasoning"],
    abstract: "We explore how generating a chain of thought -- a series of intermediate reasoning steps...",
    pdfUrl: "https://arxiv.org/pdf/2201.11903",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 91, recencyScore: 85, citations: 6000 },
  },
  {
    id: "p10",
    title: "ResNet: Deep Residual Learning",
    authors: ["He, K.", "Zhang, X.", "Ren, S."],
    year: 2016,
    venue: "CVPR",
    tags: ["Vision", "CNN", "Deep Learning"],
    abstract: "Deeper neural networks are more difficult to train. We present a residual learning framework...",
    pdfUrl: "https://arxiv.org/pdf/1512.03385",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 75, recencyScore: 40, citations: 150000 },
  },
  {
    id: "p11",
    title: "Constitutional AI",
    authors: ["Bai, Y.", "Kadavath, S.", "Kundu, S."],
    year: 2022,
    venue: "arXiv",
    tags: ["LLM", "Safety", "Alignment"],
    abstract: "We discuss a method we call Constitutional AI (CAI) for training harmless AI assistants...",
    pdfUrl: "https://arxiv.org/pdf/2212.08073",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 89, recencyScore: 90, citations: 1500 },
  },
  {
    id: "p12",
    title: "Segment Anything (SAM)",
    authors: ["Kirillov, A.", "Mintun, E.", "Ravi, N."],
    year: 2023,
    venue: "ICCV",
    tags: ["Vision", "Segmentation", "Foundation Model"],
    abstract: "We introduce the Segment Anything project: a new task, model, and dataset for image segmentation...",
    pdfUrl: "https://arxiv.org/pdf/2304.02643",
    imageUrl: "/mockup_thumb.jpg",
    metrics: { trendingScore: 97, recencyScore: 92, citations: 4000 },
  },
];

export const summaries: Summary[] = [
  {
    paperId: "p1",
    hookOneLiner: "RNN은 이제 끝! Attention만으로 번역 성능을 압도했다",
    keyPoints: [
      "Self-attention 메커니즘으로 시퀀스 전체를 병렬 처리",
      "Multi-head attention으로 다양한 관계 패턴 학습",
      "Positional encoding으로 순서 정보 보존",
      "번역 태스크에서 BLEU 점수 2점 이상 향상",
    ],
    detailed: "Transformer는 기존 RNN/LSTM 기반 seq2seq 모델의 한계를 극복합니다. Self-attention은 입력 시퀀스의 모든 위치를 동시에 참조할 수 있어 장거리 의존성 학습이 용이합니다. 특히 병렬 처리가 가능해 학습 속도가 크게 향상되었습니다.",
    evidenceScope: "full",
  },
  {
    paperId: "p2",
    hookOneLiner: "양방향 문맥 이해로 NLP 벤치마크를 싹쓸이한 모델",
    keyPoints: [
      "Masked Language Model(MLM)로 양방향 문맥 학습",
      "Next Sentence Prediction으로 문장 간 관계 이해",
      "GLUE, SQuAD 등 11개 태스크에서 SOTA 달성",
      "Fine-tuning만으로 다양한 downstream task 적용",
    ],
    detailed: "BERT는 pre-training과 fine-tuning 패러다임을 정립했습니다. 대규모 코퍼스에서 사전학습한 후, 적은 양의 라벨 데이터로 특정 태스크에 맞게 미세조정합니다.",
    evidenceScope: "full",
  },
  {
    paperId: "p3",
    hookOneLiner: "노이즈에서 시작해 고품질 이미지를 만드는 마법",
    keyPoints: [
      "Forward process: 이미지에 점진적으로 노이즈 추가",
      "Reverse process: 노이즈에서 이미지 복원 학습",
      "GAN 대비 학습 안정성과 다양성 우수",
      "고해상도 이미지 생성의 새로운 패러다임",
    ],
    detailed: "Diffusion 모델은 열역학의 확산 과정에서 영감을 받았습니다. 데이터에 점진적으로 노이즈를 추가하고, 이를 역으로 제거하는 과정을 학습합니다.",
    evidenceScope: "abstract",
  },
  {
    paperId: "p4",
    hookOneLiner: "강화학습 정책 업데이트를 안정적으로! 실무에서 가장 많이 쓰이는 알고리즘",
    keyPoints: [
      "Clipped objective로 급격한 정책 변화 방지",
      "Trust region 방식보다 구현이 단순",
      "연속/이산 행동 공간 모두 적용 가능",
      "Atari, MuJoCo 등 다양한 환경에서 검증",
    ],
    detailed: "PPO는 TRPO의 복잡한 제약 조건을 clipping으로 대체하여 구현을 단순화했습니다. 현재 OpenAI의 기본 RL 알고리즘으로 사용됩니다.",
    evidenceScope: "full",
  },
  {
    paperId: "p5",
    hookOneLiner: "이미지도 토큰화! CNN 없이 Transformer만으로 ImageNet 정복",
    keyPoints: [
      "이미지를 16x16 패치로 분할하여 토큰화",
      "위치 임베딩으로 공간 정보 보존",
      "대규모 데이터셋에서 CNN보다 우수한 성능",
      "Transfer learning에서 뛰어난 일반화 능력",
    ],
    detailed: "ViT는 NLP에서 성공한 Transformer를 컴퓨터 비전에 직접 적용했습니다. 충분한 데이터가 있으면 CNN의 inductive bias 없이도 우수한 성능을 보입니다.",
    evidenceScope: "intro",
  },
  {
    paperId: "p6",
    hookOneLiner: "텍스트와 이미지를 동시에 이해하는 초거대 멀티모달 AI",
    keyPoints: [
      "텍스트와 이미지 입력을 동시 처리",
      "전문가 수준의 시험 성적 (BAR, SAT 등)",
      "RLHF로 안전성과 유용성 개선",
      "다양한 실세계 태스크에서 인간 수준 성능",
    ],
    detailed: "GPT-4는 OpenAI의 최신 대규모 언어 모델로, 멀티모달 능력과 향상된 추론 능력을 갖추고 있습니다. RLHF를 통해 사용자 의도에 더 잘 부합하도록 훈련되었습니다.",
    evidenceScope: "abstract",
  },
  {
    paperId: "p7",
    hookOneLiner: "보상 함수 설계가 어렵다면, 인간에게 직접 물어보자",
    keyPoints: [
      "인간 피드백으로 보상 모델 학습",
      "복잡한 보상 함수 설계 문제 해결",
      "인간 선호도를 직접 최적화",
      "ChatGPT, Claude 등 LLM 정렬의 핵심 기술",
    ],
    detailed: "RLHF는 인간 평가자의 선호도 비교 데이터를 활용합니다. 두 출력 중 어느 것이 더 나은지 판단하게 하고, 이를 통해 보상 모델을 학습합니다.",
    evidenceScope: "full",
  },
  {
    paperId: "p8",
    hookOneLiner: "잠재 공간에서 확산! 고해상도 이미지를 효율적으로 생성",
    keyPoints: [
      "Latent space에서 diffusion 수행으로 계산 효율성 증가",
      "텍스트 조건부 이미지 생성 지원",
      "오픈소스로 공개되어 폭발적 확산",
      "DALL-E, Midjourney의 기반 기술",
    ],
    detailed: "Stable Diffusion은 pixel space 대신 latent space에서 diffusion을 수행합니다. 이로 인해 계산 비용이 크게 줄어들면서도 고품질 이미지 생성이 가능합니다.",
    evidenceScope: "full",
  },
  {
    paperId: "p9",
    hookOneLiner: "생각의 과정을 보여주면 수학 문제도 잘 푼다",
    keyPoints: [
      "중간 추론 단계를 명시적으로 생성",
      "산술, 상식 추론에서 성능 대폭 향상",
      "Few-shot 예시에 reasoning chain 포함",
      "모델 크기가 클수록 효과가 극대화",
    ],
    detailed: "Chain-of-Thought 프롬프팅은 복잡한 문제를 단계별로 분해하도록 유도합니다. 단순히 정답만 요구하는 것보다 추론 과정을 포함하면 정확도가 크게 향상됩니다.",
    evidenceScope: "abstract",
  },
  {
    paperId: "p10",
    hookOneLiner: "152층도 문제없다! Skip connection으로 깊은 네트워크 학습 성공",
    keyPoints: [
      "Residual connection으로 gradient vanishing 해결",
      "152층 네트워크도 안정적으로 학습",
      "ImageNet 2015 우승 (에러율 3.57%)",
      "현대 딥러닝 아키텍처의 기본 구성 요소",
    ],
    detailed: "ResNet은 입력을 출력에 직접 더하는 skip connection을 도입했습니다. 이로 인해 네트워크가 잔차(residual)만 학습하면 되어 최적화가 쉬워집니다.",
    evidenceScope: "full",
  },
  {
    paperId: "p11",
    hookOneLiner: "AI가 스스로 자신을 교정하는 헌법적 AI",
    keyPoints: [
      "명시적 원칙(헌법)에 따라 출력 수정",
      "인간 피드백 의존도 감소",
      "Helpful, Harmless, Honest 목표",
      "Red teaming 공격에 대한 강건성 향상",
    ],
    detailed: "Constitutional AI는 AI 시스템이 스스로 출력을 평가하고 수정하도록 합니다. 사전에 정의된 원칙들을 기준으로 자기 비평을 수행합니다.",
    evidenceScope: "abstract",
  },
  {
    paperId: "p12",
    hookOneLiner: "프롬프트 하나로 어떤 물체든 분할하는 만능 세그멘테이션",
    keyPoints: [
      "Point, box, text 등 다양한 프롬프트 지원",
      "11M 이미지, 1.1B 마스크로 학습",
      "Zero-shot 일반화 능력",
      "의료, 위성 등 다양한 도메인에 적용 가능",
    ],
    detailed: "SAM은 프롬프트 기반 세그멘테이션을 수행합니다. 특정 도메인에 대한 학습 없이도 다양한 이미지에서 물체를 정확하게 분할할 수 있습니다.",
    evidenceScope: "full",
  },
];

export const reports: Report[] = [
  {
    id: "r1",
    title: "2024년 LLM 트렌드: 멀티모달과 에이전트의 시대",
    summary: "GPT-4V, Gemini 등 멀티모달 모델이 주류가 되고, AutoGPT 같은 에이전트 시스템이 부상하고 있습니다. 작은 모델의 효율성 연구도 활발합니다.",
    tags: ["LLM", "Multimodal", "Agent"],
    relatedPaperIds: ["p6", "p9"],
    imageUrl: "/mockup_thumb.jpg",
  },
  {
    id: "r2",
    title: "Diffusion 모델의 진화: 이미지에서 비디오까지",
    summary: "Stable Diffusion의 성공 이후, Sora 같은 비디오 생성 모델이 등장했습니다. 3D 생성과 컨트롤러블 생성이 차세대 연구 방향입니다.",
    tags: ["Diffusion", "Vision", "Generative"],
    relatedPaperIds: ["p3", "p8"],
    imageUrl: "/mockup_thumb.jpg",
  },
  {
    id: "r3",
    title: "RL의 새로운 물결: RLHF에서 DPO까지",
    summary: "LLM 정렬에서 RLHF가 표준이 되었지만, DPO 같은 더 단순한 방법들도 등장하고 있습니다. 인간 피드백 없는 정렬 연구도 진행 중입니다.",
    tags: ["RL", "RLHF", "Alignment"],
    relatedPaperIds: ["p4", "p7", "p11"],
    imageUrl: "/mockup_thumb.jpg",
  },
];

export const allTags = [
  "Transformer", "NLP", "Vision", "RL", "Diffusion", 
  "LLM", "Generative", "Attention", "CNN", "RLHF",
  "Multimodal", "Prompting", "Safety", "Segmentation"
];
